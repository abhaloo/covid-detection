{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covid-detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAaBfRCV9urd"
      },
      "source": [
        "Import statement for Tensorflow to work in colab\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5KlEjcJ9mxK"
      },
      "source": [
        "try:\r\n",
        "  # %tensorflow_version only exists in Colab.\r\n",
        "  %tensorflow_version 2.x\r\n",
        "except Exception:\r\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFb5epfLCM0q"
      },
      "source": [
        "Downloading necessary modules needed to run this project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t40qNDME1sb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b99ea00d-419c-47d7-b5c6-936a41103ee9"
      },
      "source": [
        "!pip install split-folders\r\n",
        "!pip install opencv-python\r\n",
        "!pip install pool"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/5f/3c2b2f7ea5e047c8cdc3bb00ae582c5438fcdbbedcc23b3cc1c2c7aae642/split_folders-0.4.3-py3-none-any.whl\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.3\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.19.4)\n",
            "Collecting pool\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/b4/b7c44381e6e074a01c004ecd6d7b668037821abaf17a787fc01cdf9256a7/pool-0.1.2dev.tar.gz\n",
            "Building wheels for collected packages: pool\n",
            "  Building wheel for pool (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pool: filename=pool-0.1.2.dev0-cp36-none-any.whl size=23391 sha256=3e30393b48569ac13474504aeedcc5b05e4951402dcb75bd73fb3a05b1a67c0c\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/d3/fd/28866af580c0f46a2a629080265b0c72758d09843ac49e0a8e\n",
            "Successfully built pool\n",
            "Installing collected packages: pool\n",
            "Successfully installed pool-0.1.2.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGVb6lH66Dh-"
      },
      "source": [
        "Image Augmentation function to generate transformations of images for training the model better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhDuO_Lipnho"
      },
      "source": [
        "from random import random\r\n",
        "from keras_preprocessing.image import ImageDataGenerator, np\r\n",
        "\r\n",
        "# Image will be rotated by upto 365 degrees. The image will also be shifting\r\n",
        "# left and right by 5 pixels. This will generate a bigger dataset to run\r\n",
        "# CNN on. Possible to generate 146000 images from one image. \r\n",
        "def imageAugmentation(image):\r\n",
        "    seed = int(random() * 100000000)\r\n",
        "    wShift = 5\r\n",
        "    hShift = 5\r\n",
        "    # rotation is changing values of image\r\n",
        "    imgen = ImageDataGenerator(\r\n",
        "                                 rotation_range=365,\r\n",
        "                                 width_shift_range=wShift,\r\n",
        "                                 height_shift_range=hShift,\r\n",
        "                                 horizontal_flip=True,\r\n",
        "                                 vertical_flip=True,\r\n",
        "                                 fill_mode='constant',\r\n",
        "                                 cval=0)\r\n",
        "    image = imgen.random_transform(image, seed)\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNzpPbU953LI"
      },
      "source": [
        "Importing all the necessary packages in order to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdsYRZo7CMOW"
      },
      "source": [
        "# Importing necessary packages\r\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\r\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\r\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D,MaxPooling2D\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from keras.backend import clear_session\r\n",
        "from glob import glob\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import splitfolders\r\n",
        "import cv2\r\n",
        "import random\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p7904Z95Zyh"
      },
      "source": [
        "Splitting the input data and building the array containing images to be used for training and validation\r\n",
        "\r\n",
        "Image parsing adapted from https://github.com/appushona123/Instant-COVID19-detection/blob/master/covid19_hackathon.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULS3K-ye5ZTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dd3659d-338d-4dbc-9e32-036b5c5cd489"
      },
      "source": [
        "print(\"--Get data--\")\r\n",
        "# split Covid and Non-Covid images into training and testing categories\r\n",
        "# using 70% for training (521 files) and 30% for testing/validation (225 files)\r\n",
        "splitfolders.ratio(\"data\", output=\"data-split\", seed=1337, ratio=(.7,.3), group_prefix=None) # default values\r\n",
        "\r\n",
        "# np.zeroes arguments: number of files, len, width, color_dimension\r\n",
        "# initialize training and testing numpy arrays for loading data\r\n",
        "x_train_temp = np.zeros((521, 256, 256, 3))\r\n",
        "y_train_temp = np.zeros((521, 1))\r\n",
        "x_test_temp = np.zeros((225, 256, 256, 3))\r\n",
        "y_test_temp = np.zeros((225, 1))\r\n",
        "\r\n",
        "\r\n",
        "# Load images\r\n",
        "train_covid_path = glob('/content/data-split/train/CT_COVID/*')\r\n",
        "train_normal_path = glob('/content/data-split/train/CT_NonCOVID/*')\r\n",
        "test_covid_path = glob('/content/data-split/val/CT_COVID/*')\r\n",
        "test_normal_path = glob('/content/data-split/val/CT_NonCOVID/*')\r\n",
        "\r\n",
        "# Building the training array\r\n",
        "i = 0    # index\r\n",
        "for img_file in train_covid_path:\r\n",
        "    image_orig = cv2.imread(img_file)\r\n",
        "    image_resized = cv2.resize(image_orig, (256, 256), interpolation=cv2.INTER_CUBIC)\r\n",
        "    img_array = img_to_array(image_resized)\r\n",
        "\r\n",
        "    x_train_temp[i] = img_array / 255    # Normalization\r\n",
        "    y_train_temp[i] = 1\r\n",
        "    i += 1\r\n",
        "\r\n",
        "for img_file in train_normal_path:\r\n",
        "    image_orig = cv2.imread(img_file)\r\n",
        "    image_resized = cv2.resize(image_orig, (256, 256), interpolation=cv2.INTER_CUBIC)\r\n",
        "    img_array = img_to_array(image_resized)\r\n",
        "\r\n",
        "    x_train_temp[i] = img_array / 255\r\n",
        "    y_train_temp[i] = 0\r\n",
        "    i += 1\r\n",
        "\r\n",
        "# Building the validation array\r\n",
        "j = 0   # index\r\n",
        "for img_file in test_covid_path:\r\n",
        "    image_orig = cv2.imread(img_file)\r\n",
        "    image_resized = cv2.resize(image_orig, (256, 256), interpolation=cv2.INTER_CUBIC)\r\n",
        "    img_array = img_to_array(image_resized)\r\n",
        "\r\n",
        "    x_test_temp[j] = img_array / 255   \r\n",
        "    y_test_temp[j] = 1\r\n",
        "    j += 1\r\n",
        "\r\n",
        "for img_file in test_normal_path:\r\n",
        "    image_orig = cv2.imread(img_file)\r\n",
        "    image_resized = cv2.resize(image_orig, (256, 256), interpolation=cv2.INTER_CUBIC)\r\n",
        "    img_array = img_to_array(image_resized)\r\n",
        "\r\n",
        "    x_test_temp[j] = img_array / 255   \r\n",
        "    y_test_temp[j] = 0\r\n",
        "    j += 1\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying files: 208 files [00:00, 2062.52 files/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--Get data--\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying files: 746 files [00:00, 2977.85 files/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZifUmQq5aru"
      },
      "source": [
        "Shuffling the training and validation arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbcQ8rEh5a6t"
      },
      "source": [
        "# Shuffling the train and validation array\r\n",
        "\r\n",
        "#initialize arrays for after data shuffle\r\n",
        "x_train = np.zeros((521, 256, 256, 3))\r\n",
        "y_train = np.zeros((521, 1))\r\n",
        "x_test = np.zeros((225, 256, 256, 3))\r\n",
        "y_test = np.zeros((225, 1))\r\n",
        "\r\n",
        "#create indices arrays\r\n",
        "train_indices = [x for x in range(0, 521)]\r\n",
        "test_indicies = [x for x in range(0, 225)]\r\n",
        "\r\n",
        "#shuffle indicies\r\n",
        "random.shuffle(train_indices)\r\n",
        "random.shuffle(test_indicies)\r\n",
        "\r\n",
        "#populate arrays\r\n",
        "for ind, num in enumerate(train_indices):\r\n",
        "    x_train[ind] = x_train_temp[num]\r\n",
        "    y_train[ind] = y_train_temp[num]\r\n",
        "\r\n",
        "for ind, num in enumerate(test_indicies):\r\n",
        "    x_test[ind] = x_test_temp[num]\r\n",
        "    y_test[ind] = y_test_temp[num]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hVxKoA55bbS"
      },
      "source": [
        "Function to build the CNN Model being used for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vOBGkf85bkf"
      },
      "source": [
        "# Build CNN model\r\n",
        "def build_model(input_shape, classes=1):\r\n",
        "    img_input = Input(shape=input_shape)\r\n",
        "    # Block 1\r\n",
        "    x = Conv2D(64, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block1_conv1')(img_input)\r\n",
        "    x = Conv2D(64, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block1_conv2')(x)\r\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\r\n",
        "\r\n",
        "    # Block 2\r\n",
        "    x = Conv2D(128, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block2_conv1')(x)\r\n",
        "    x = Conv2D(128, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block2_conv2')(x)\r\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\r\n",
        "\r\n",
        "    # Block 3\r\n",
        "    x = Conv2D(256, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block3_conv1')(x)\r\n",
        "    x = Conv2D(256, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block3_conv2')(x)\r\n",
        "    x = Conv2D(256, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block3_conv3')(x)\r\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\r\n",
        "\r\n",
        "    # Block 4\r\n",
        "    x = Conv2D(512, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block4_conv1')(x)\r\n",
        "    x = Conv2D(512, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block4_conv2')(x)\r\n",
        "    x = Conv2D(512, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block4_conv3')(x)\r\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\r\n",
        "\r\n",
        "    # Block 5\r\n",
        "    x = Conv2D(512, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block5_conv1')(x)\r\n",
        "    x = Conv2D(512, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block5_conv2')(x)\r\n",
        "    x = Conv2D(512, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block5_conv3')(x)\r\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\r\n",
        "\r\n",
        "    x = Flatten(name='flatten')(x)\r\n",
        "    x = Dense(4096, activation='relu', name='fc1')(x)\r\n",
        "    x = Dense(4096, activation='relu', name='fc2')(x)\r\n",
        "    x = Dense(classes, activation='sigmoid', name='predictions')(x)\r\n",
        "    model = Model(img_input,x, name=\"vgg16_Covid\")\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5pelQ1Z6d3A"
      },
      "source": [
        "Building the model, training and evaluating it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWpaXgfh6d-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4abedbf-a41a-45d4-84ec-16c7d8668e2b"
      },
      "source": [
        "clear_session()\r\n",
        "model = build_model(x_train.shape[1:])\r\n",
        "# opt = tf.keras.optimizers.Adam(lr=0.01, decay=1e-6)\r\n",
        "# sgd = tf.keras.optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\r\n",
        "model.compile(optimizer = 'adam', loss ='binary_crossentropy', metrics = ['accuracy'])\r\n",
        "\r\n",
        "print(\"-- Fit model--\")\r\n",
        "model.fit(x_train, y_train, batch_size = 16, epochs = 20, verbose = 1)\r\n",
        "\r\n",
        "# Model performance evaluation\r\n",
        "\r\n",
        "print(\"-- Evaluate model--\")\r\n",
        "\r\n",
        "model_loss, model_acc = model.evaluate(x_test, y_test, verbose=2)\r\n",
        "print(f\"Model Loss:    {model_loss:.2f}\")\r\n",
        "print(f\"Model Accuracy: {model_acc*100:.1f}%\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Fit model--\n",
            "Epoch 1/20\n",
            "33/33 [==============================] - 19s 301ms/step - loss: 3.1067 - accuracy: 0.4197\n",
            "Epoch 2/20\n",
            "33/33 [==============================] - 9s 265ms/step - loss: 0.6929 - accuracy: 0.5266\n",
            "Epoch 3/20\n",
            "33/33 [==============================] - 9s 265ms/step - loss: 0.6908 - accuracy: 0.5480\n",
            "Epoch 4/20\n",
            "33/33 [==============================] - 9s 263ms/step - loss: 0.6885 - accuracy: 0.5709\n",
            "Epoch 5/20\n",
            "33/33 [==============================] - 9s 264ms/step - loss: 0.6949 - accuracy: 0.4933\n",
            "Epoch 6/20\n",
            "33/33 [==============================] - 9s 266ms/step - loss: 0.6916 - accuracy: 0.5419\n",
            "Epoch 7/20\n",
            "33/33 [==============================] - 9s 266ms/step - loss: 0.6880 - accuracy: 0.5747\n",
            "Epoch 8/20\n",
            "33/33 [==============================] - 9s 267ms/step - loss: 0.6900 - accuracy: 0.5448\n",
            "Epoch 9/20\n",
            "33/33 [==============================] - 9s 269ms/step - loss: 0.6872 - accuracy: 0.5823\n",
            "Epoch 10/20\n",
            "33/33 [==============================] - 9s 268ms/step - loss: 0.6944 - accuracy: 0.5003\n",
            "Epoch 11/20\n",
            "33/33 [==============================] - 9s 269ms/step - loss: 0.6928 - accuracy: 0.5148\n",
            "Epoch 12/20\n",
            "33/33 [==============================] - 9s 270ms/step - loss: 0.6885 - accuracy: 0.5546\n",
            "Epoch 13/20\n",
            "33/33 [==============================] - 9s 271ms/step - loss: 0.6898 - accuracy: 0.5437\n",
            "Epoch 14/20\n",
            "33/33 [==============================] - 9s 270ms/step - loss: 0.6909 - accuracy: 0.5355\n",
            "Epoch 15/20\n",
            "33/33 [==============================] - 9s 271ms/step - loss: 0.6912 - accuracy: 0.5337\n",
            "Epoch 16/20\n",
            "33/33 [==============================] - 9s 273ms/step - loss: 0.6888 - accuracy: 0.5517\n",
            "Epoch 17/20\n",
            "33/33 [==============================] - 9s 275ms/step - loss: 0.6917 - accuracy: 0.5273\n",
            "Epoch 18/20\n",
            "33/33 [==============================] - 9s 274ms/step - loss: 0.6928 - accuracy: 0.5164\n",
            "Epoch 19/20\n",
            "33/33 [==============================] - 9s 275ms/step - loss: 0.6932 - accuracy: 0.5156\n",
            "Epoch 20/20\n",
            "33/33 [==============================] - 9s 275ms/step - loss: 0.6921 - accuracy: 0.5271\n",
            "-- Evaluate model--\n",
            "8/8 - 3s - loss: 0.6909 - accuracy: 0.5333\n",
            "Model Loss:    0.69\n",
            "Model Accuracy: 53.3%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}