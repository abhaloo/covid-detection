{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covid-detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAaBfRCV9urd"
      },
      "source": [
        "Import statement for Tensorflow to work in colab\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5KlEjcJ9mxK"
      },
      "source": [
        "try:\r\n",
        "  # %tensorflow_version only exists in Colab.\r\n",
        "  %tensorflow_version 2.x\r\n",
        "except Exception:\r\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFb5epfLCM0q"
      },
      "source": [
        "Downloading necessary modules needed to run this project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t40qNDME1sb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5bb4a13-d78c-4b2c-85d2-f6f170b3dd97"
      },
      "source": [
        "!pip install split-folders\r\n",
        "!pip install opencv-python\r\n",
        "!pip install pool"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/5f/3c2b2f7ea5e047c8cdc3bb00ae582c5438fcdbbedcc23b3cc1c2c7aae642/split_folders-0.4.3-py3-none-any.whl\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.3\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.19.4)\n",
            "Collecting pool\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/b4/b7c44381e6e074a01c004ecd6d7b668037821abaf17a787fc01cdf9256a7/pool-0.1.2dev.tar.gz\n",
            "Building wheels for collected packages: pool\n",
            "  Building wheel for pool (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pool: filename=pool-0.1.2.dev0-cp36-none-any.whl size=23391 sha256=9242c8b1a982ebdfc0080b9f37ecbccbb564a4b06eafb474a9de1c2b52d0653e\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/d3/fd/28866af580c0f46a2a629080265b0c72758d09843ac49e0a8e\n",
            "Successfully built pool\n",
            "Installing collected packages: pool\n",
            "Successfully installed pool-0.1.2.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGVb6lH66Dh-"
      },
      "source": [
        "Image Augmentation function to generate transformations of images for training the model better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhDuO_Lipnho"
      },
      "source": [
        "from random import random\r\n",
        "from keras_preprocessing.image import ImageDataGenerator, np\r\n",
        "\r\n",
        "# Image will be rotated by upto 365 degrees. The image will also be shifting\r\n",
        "# left and right by 5 pixels. This will generate a bigger dataset to run\r\n",
        "# CNN on. Possible to generate 146000 images from one image. \r\n",
        "def imageAugmentation(image):\r\n",
        "    seed = int(random() * 100000000)\r\n",
        "    wShift = 5\r\n",
        "    hShift = 5\r\n",
        "    # rotation is changing values of image\r\n",
        "    imgen = ImageDataGenerator(\r\n",
        "                                 rotation_range=365,\r\n",
        "                                 width_shift_range=wShift,\r\n",
        "                                 height_shift_range=hShift,\r\n",
        "                                 horizontal_flip=True,\r\n",
        "                                 vertical_flip=True,\r\n",
        "                                 fill_mode='constant',\r\n",
        "                                 cval=0)\r\n",
        "    image = imgen.random_transform(image, seed)\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNzpPbU953LI"
      },
      "source": [
        "Importing all the necessary packages in order to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdsYRZo7CMOW"
      },
      "source": [
        "# Importing necessary packages\r\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\r\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\r\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D,MaxPooling2D\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from keras.backend import clear_session\r\n",
        "from glob import glob\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import splitfolders\r\n",
        "import cv2\r\n",
        "import random\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p7904Z95Zyh"
      },
      "source": [
        "Splitting the input data and building the array containing images to be used for training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULS3K-ye5ZTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e31458d-316b-4a98-f254-ad2617bc5700"
      },
      "source": [
        "print(\"--Get data--\")\r\n",
        "# split Covid and Non-Covid images into training and testing categories\r\n",
        "# using 70% for training (521 files) and 30% for testing/validation (225 files)\r\n",
        "splitfolders.ratio(\"data\", output=\"data-split\", seed=1337, ratio=(.7,.3), group_prefix=None) # default values\r\n",
        "\r\n",
        "# np.zeroes arguments: number of files, len, width, color_dimension\r\n",
        "# initialize training and testing numpy arrays for loading data\r\n",
        "x_train_temp = np.zeros((521, 256, 256, 3))\r\n",
        "y_train_temp = np.zeros((521, 1))\r\n",
        "x_test_temp = np.zeros((225, 256, 256, 3))\r\n",
        "y_test_temp = np.zeros((225, 1))\r\n",
        "\r\n",
        "\r\n",
        "# Load images\r\n",
        "train_covid_path = glob('/content/data-split/train/CT_COVID/*')\r\n",
        "train_normal_path = glob('/content/data-split/train/CT_NonCOVID/*')\r\n",
        "test_covid_path = glob('/content/data-split/val/CT_COVID/*')\r\n",
        "test_normal_path = glob('/content/data-split/val/CT_NonCOVID/*')\r\n",
        "\r\n",
        "# Building the training array\r\n",
        "cnt = 0\r\n",
        "for img_file in train_covid_path:\r\n",
        "    image_orig = cv2.imread(img_file)\r\n",
        "    image_resized = cv2.resize(image_orig, (256, 256), interpolation=cv2.INTER_CUBIC)\r\n",
        "    img_array = img_to_array(image_resized)\r\n",
        "\r\n",
        "    x_train_temp[cnt] = img_array / 255\r\n",
        "    y_train_temp[cnt] = 1\r\n",
        "    cnt += 1\r\n",
        "\r\n",
        "for img_file in train_normal_path:\r\n",
        "    image_orig = cv2.imread(img_file)\r\n",
        "    image_resized = cv2.resize(image_orig, (256, 256), interpolation=cv2.INTER_CUBIC)\r\n",
        "    img_array = img_to_array(image_resized)\r\n",
        "\r\n",
        "    x_train_temp[cnt] = img_array / 255\r\n",
        "    y_train_temp[cnt] = 0\r\n",
        "    cnt += 1\r\n",
        "\r\n",
        "# Building the validation array\r\n",
        "cnt2 = 0 #index\r\n",
        "for img_file in test_covid_path:\r\n",
        "    image_orig = cv2.imread(img_file)\r\n",
        "    image_resized = cv2.resize(image_orig, (256, 256), interpolation=cv2.INTER_CUBIC)\r\n",
        "    img_array = img_to_array(image_resized)\r\n",
        "\r\n",
        "    x_test_temp[cnt2] = img_array / 255   # Normalization\r\n",
        "    y_test_temp[cnt2] = 1\r\n",
        "    cnt2 += 1\r\n",
        "\r\n",
        "for img_file in test_normal_path:\r\n",
        "    image_orig = cv2.imread(img_file)\r\n",
        "    image_resized = cv2.resize(image_orig, (256, 256), interpolation=cv2.INTER_CUBIC)\r\n",
        "    img_array = img_to_array(image_resized)\r\n",
        "\r\n",
        "    x_test_temp[cnt2] = img_array / 255   # Normalization\r\n",
        "    y_test_temp[cnt2] = 0\r\n",
        "    cnt += 1\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying files: 746 files [00:00, 4395.56 files/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--Get data--\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZifUmQq5aru"
      },
      "source": [
        "Shuffling the training and validation arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbcQ8rEh5a6t"
      },
      "source": [
        "# Shuffling the train and validation array\r\n",
        "\r\n",
        "#initialize arrays for after data shuffle\r\n",
        "x_train = np.zeros((521, 256, 256, 3))\r\n",
        "y_train = np.zeros((521, 1))\r\n",
        "x_test = np.zeros((225, 256, 256, 3))\r\n",
        "y_test = np.zeros((225, 1))\r\n",
        "\r\n",
        "#create indices arrays\r\n",
        "train_indices = [x for x in range(0, 521)]\r\n",
        "test_indicies = [x for x in range(0, 225)]\r\n",
        "\r\n",
        "#shuffle indicies\r\n",
        "random.shuffle(train_indices)\r\n",
        "random.shuffle(test_indicies)\r\n",
        "\r\n",
        "#populate arrays\r\n",
        "for ind, num in enumerate(train_indices):\r\n",
        "    x_train[ind] = x_train_temp[num]\r\n",
        "    y_train[ind] = y_train_temp[num]\r\n",
        "\r\n",
        "for ind, num in enumerate(test_indicies):\r\n",
        "    x_test[ind] = x_test_temp[num]\r\n",
        "    y_test[ind] = y_test_temp[num]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hVxKoA55bbS"
      },
      "source": [
        "Function to build the CNN Model being used for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vOBGkf85bkf"
      },
      "source": [
        "# Build CNN model\r\n",
        "def build_model(input_shape, classes=1):\r\n",
        "    img_input = Input(shape=input_shape)\r\n",
        "    # Block 1\r\n",
        "    x = Conv2D(64, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block1_conv1')(img_input)\r\n",
        "    x = Conv2D(64, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block1_conv2')(x)\r\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\r\n",
        "\r\n",
        "    # Block 2\r\n",
        "    x = Conv2D(128, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block2_conv1')(x)\r\n",
        "    x = Conv2D(128, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block2_conv2')(x)\r\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\r\n",
        "\r\n",
        "    # Block 3\r\n",
        "    x = Conv2D(256, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block3_conv1')(x)\r\n",
        "    x = Conv2D(256, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block3_conv2')(x)\r\n",
        "    x = Conv2D(256, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block3_conv3')(x)\r\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\r\n",
        "\r\n",
        "    # Block 4\r\n",
        "    x = Conv2D(512, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block4_conv1')(x)\r\n",
        "    x = Conv2D(512, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block4_conv2')(x)\r\n",
        "    x = Conv2D(512, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block4_conv3')(x)\r\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\r\n",
        "\r\n",
        "    # Block 5\r\n",
        "    x = Conv2D(512, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block5_conv1')(x)\r\n",
        "    x = Conv2D(512, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block5_conv2')(x)\r\n",
        "    x = Conv2D(512, (3, 3),\r\n",
        "                      activation='relu',\r\n",
        "                      padding='same',\r\n",
        "                      name='block5_conv3')(x)\r\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\r\n",
        "\r\n",
        "    x = Flatten(name='flatten')(x)\r\n",
        "    x = Dense(4096, activation='relu', name='fc1')(x)\r\n",
        "    x = Dense(4096, activation='relu', name='fc2')(x)\r\n",
        "    x = Dense(classes, activation='sigmoid', name='predictions')(x)\r\n",
        "    model = Model(img_input,x, name=\"vgg16_Covid\")\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5pelQ1Z6d3A"
      },
      "source": [
        "Building the model, training and evaluating it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWpaXgfh6d-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4182799d-a065-4f82-b09b-144d96bd1879"
      },
      "source": [
        "clear_session()\r\n",
        "model = build_model(x_train.shape[1:])\r\n",
        "# opt = tf.keras.optimizers.Adam(lr=0.01, decay=1e-6)\r\n",
        "# sgd = tf.keras.optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\r\n",
        "model.compile(optimizer = 'adam', loss ='binary_crossentropy', metrics = ['accuracy'])\r\n",
        "\r\n",
        "print(\"-- Fit model--\")\r\n",
        "model.fit(x_train, y_train, batch_size = 16, epochs = 20, verbose = 1)\r\n",
        "\r\n",
        "# Model performance evaluation\r\n",
        "\r\n",
        "print(\"-- Evaluate model--\")\r\n",
        "\r\n",
        "model_loss, model_acc = model.evaluate(x_test, y_test, verbose=2)\r\n",
        "print(f\"Model Loss:    {model_loss:.2f}\")\r\n",
        "print(f\"Model Accuracy: {model_acc*100:.1f}%\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Fit model--\n",
            "Epoch 1/20\n",
            "33/33 [==============================] - 19s 294ms/step - loss: 0.9435 - accuracy: 0.4877\n",
            "Epoch 2/20\n",
            "33/33 [==============================] - 9s 258ms/step - loss: 0.6925 - accuracy: 0.5430\n",
            "Epoch 3/20\n",
            "33/33 [==============================] - 8s 255ms/step - loss: 0.6924 - accuracy: 0.5265\n",
            "Epoch 4/20\n",
            "33/33 [==============================] - 8s 256ms/step - loss: 0.6925 - accuracy: 0.5201\n",
            "Epoch 5/20\n",
            "33/33 [==============================] - 9s 257ms/step - loss: 0.6929 - accuracy: 0.5220\n",
            "Epoch 6/20\n",
            "33/33 [==============================] - 9s 258ms/step - loss: 0.6902 - accuracy: 0.5388\n",
            "Epoch 7/20\n",
            "33/33 [==============================] - 9s 260ms/step - loss: 0.6920 - accuracy: 0.5289\n",
            "Epoch 8/20\n",
            "33/33 [==============================] - 9s 261ms/step - loss: 0.6899 - accuracy: 0.5436\n",
            "Epoch 9/20\n",
            "33/33 [==============================] - 9s 262ms/step - loss: 0.6861 - accuracy: 0.5712\n",
            "Epoch 10/20\n",
            "33/33 [==============================] - 9s 262ms/step - loss: 0.6915 - accuracy: 0.5317\n",
            "Epoch 11/20\n",
            "33/33 [==============================] - 9s 265ms/step - loss: 0.6914 - accuracy: 0.5322\n",
            "Epoch 12/20\n",
            "33/33 [==============================] - 9s 267ms/step - loss: 0.6895 - accuracy: 0.5418\n",
            "Epoch 13/20\n",
            "33/33 [==============================] - 9s 267ms/step - loss: 0.6938 - accuracy: 0.5030\n",
            "Epoch 14/20\n",
            "33/33 [==============================] - 9s 269ms/step - loss: 0.6864 - accuracy: 0.5705\n",
            "Epoch 15/20\n",
            "33/33 [==============================] - 9s 270ms/step - loss: 0.6942 - accuracy: 0.5095\n",
            "Epoch 16/20\n",
            "33/33 [==============================] - 9s 270ms/step - loss: 0.6926 - accuracy: 0.5172\n",
            "Epoch 17/20\n",
            "33/33 [==============================] - 9s 271ms/step - loss: 0.6915 - accuracy: 0.5306\n",
            "Epoch 18/20\n",
            "33/33 [==============================] - 9s 273ms/step - loss: 0.6914 - accuracy: 0.5308\n",
            "Epoch 19/20\n",
            "33/33 [==============================] - 9s 274ms/step - loss: 0.6918 - accuracy: 0.5287\n",
            "Epoch 20/20\n",
            "33/33 [==============================] - 9s 274ms/step - loss: 0.6925 - accuracy: 0.5279\n",
            "-- Evaluate model--\n",
            "8/8 - 3s - loss: 0.6909 - accuracy: 0.5333\n",
            "Model Loss:    0.69\n",
            "Model Accuracy: 53.3%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}